
import os 
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import AIMessage
from langchain_core.prompts import PromptTemplate

from .prompts import template

# Importamos los nuevos esquemas del estado
from src.agents.tech_surveillance.state import GraphState, CallInfo

# ... (definici√≥n de chat_model y extraction_llm sin cambios) ...
chat_model = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    api_key=os.environ.get("GEMINI_API_KEY"),
    temperature=0.0, # Reduced temperature for more deterministic extraction
    convert_system_message_to_human=True
)
extraction_llm = chat_model.with_structured_output(CallInfo)


def ingestion_node(state: GraphState) -> dict:
    """
    Se activa cuando se detecta un nuevo proyecto o convocatoria. 
    Extrae la informaci√≥n de la convocatoria y estructura el estado.
    """
    print("--- Ejecutando Nodo: Ingesta de Convocatoria ---")
    last_message = state["messages"][-1].content
    
    prompt_template = PromptTemplate.from_template(template, partial_variables={"last_message": last_message})
    prompt = prompt_template.format()
    
    try:
        # 1. Llama al LLM para extraer la informaci√≥n (Call Info Only)
        ingestion_result: CallInfo = extraction_llm.invoke(prompt)
        
        # 2. Prepara el mensaje de confirmaci√≥n
        confirmation_text = ""
        
        if ingestion_result:
            confirmation_text += f"‚úÖ **Convocatoria Detectada:** {ingestion_result.title}\n"
            if ingestion_result.url:
                confirmation_text += f"üîó **URL:** {ingestion_result.url}\n"
            confirmation_text += "\n"
            confirmation_text += "He identificado la informaci√≥n de la convocatoria. ¬øDeseas proceder con alguna acci√≥n espec√≠fica?"
        else:
            confirmation_text = "No he detectado informaci√≥n clara sobre una convocatoria en tu mensaje. Por favor, proporciona m√°s detalles."

        # 3. Preservar documentos de contexto si ya existen en el estado
        old_call_info = state.get("call_info")
        if old_call_info and ingestion_result:
            # Manejar tanto si es objeto como dict
            if hasattr(old_call_info, "context_docs") and old_call_info.context_docs:
                ingestion_result.context_docs = old_call_info.context_docs
            elif isinstance(old_call_info, dict) and old_call_info.get("context_docs"):
                ingestion_result.context_docs = old_call_info["context_docs"]

        # 4. Devuelve la nueva estructura del estado
        return {
            "call_info": ingestion_result, # Guardamos la info de la convocatoria en el estado
            "messages": [AIMessage(content=confirmation_text)]
        }

    except Exception as e:
        print(f"--- Error en el Nodo de Ingesta: {e} ---")
        error_message = AIMessage(
            content="Hubo un problema procesando la informaci√≥n de la convocatoria."
        )
        return {"messages": [error_message]}
